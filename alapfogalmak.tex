%!TEX root = minta_dolgozat.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Alapfogalmak}\label{ch:ALAPFOGALMAK}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{osszefoglal}
	E fejezet célja bemutatni röviden a megerősítéses tanulást. E mellett bemutatásra kerülnek a megerősítéses tanulási algoritmusok alaplépései, illetve a RoboRun projekttel kapcsolatos néhány alap fogalom és ezek használata a projekt során.
\end{osszefoglal}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A megerősítéses tanulás}\label{sec:MEGEROSITESESTANULAS}
Már az 1950 - es évek előtt foglalkoztak mesterséges intelligencia kutatással, csak akkor még nem így nevezték. Az 1950 - es években John McCarthy\footnote{\href {http://en.wikipedia.org/wiki/Marvin_Minsky}{http://en.wikipedia.org/wiki/John\_McCarthy\_\%28computer\_scientist\%29}} megalkotja a mesterséges intelligencia kifejezést. Az intelligencia fogalmát Marvin Minsky\footnote{\href {http://en.wikipedia.org/wiki/Marvin\_Minsky}{http://en.wikipedia.org/wiki/Marvin\_Minsky}} a következőképpen definiálta: "Az intelligencia egy gyakran használt fogalom annak a rejtélynek a kifejezésére, hogy néhány önálló elem, vagy elemek felelősek a személy következtetési képességéért. Én jobban szeretem úgy elképzelni ezt, mint amely nemcsak valami különös erőt, vagy tüneményt reprezentál, hanem egyszerűen az összes mentális képességet, amelyet mi minden pillanatban megcsodálhatunk, de még nem értettünk meg." 
	
	Az ember már nagyon rég próbálkozik azzal, hogy a természettől kapott képességeit, mesterséges eszközökbe beültesse, illetve ezen eszközök segítségével kibővítse. Ennek megvalósítására a számítógépek megjelenésével nyílt igazán jó lehetőség. A számítógépek lehetőséget biztosítanak arra, hogy az emberi intelligenciát részben helyettesítsék. Rengeteg kutatás és kísérletezés folyik ennek érdekében.	
	
	A gépi tanulás is a természetből indul ki. Az élő szervezetet próbálja modellezni. Ezen algoritmusok legfőbb jellemzője az adaptációs\footnote{\href {http://hu.wikipedia.org/wiki/Adaptáció}{http://hu.wikipedia.org/wiki/Adaptáció}} tanulási képesség. A tanulás és az adaptáció valójában az élő szervezet működését jellemzi, ahogyan az ember is megszerzett ismeretek és tapasztalatok alapján cselekszik. Tanulásról beszélünk abban az esetben is, ha tapasztalatok sorozata kerül megtanulásra, illetve abban az esetben is amennyiben előző tapasztalatok alapján képes különböző döntések meghozatalára. 
	
	 Ahogyan az élő szervezeteknél, úgy a gépeknél is többfajta tanulásról beszélhetünk. Például a neurális hálók\footnote{\href {http://hu.wikipedia.org/wiki/Neurális\_hálózat}{http://hu.wikipedia.org/wiki/Neurális\_hálózat}} esetén minták alapján történik a tanulás. Ez azt jelenti, hogy nagy mennyiségű adatból próbálunk megfelelő mennyiségű ismeretet szerezni és ezáltal befolyásolni a rendszer működését. A rendszer működésének befolyásolása több dologra is irányulhat. Például, hogy a rendszer adott bemenetekre, előre megadott válaszokat produkál- e. Lehet olyan eset is, amikor azt szeretnénk tesztelni, hogy a rendszer képes- e adott bemenetekre valamilyen szabályosságot felállítani. Ezen algoritmusokat gyakran helyezik változó környezetekbe és azt tesztelik, hogy mennyire képesek alkalmazkodni az új környezethez. 	
	
	 A mesterséges intelligencia esetén beszélhetünk felügyelt, nem felügyelt és félig felügyelt tanulási módszerekről. A megerősítéses tanulás a nem felügyelt tanulási ágat képviseli. A nem felügyelt tanulás esetén nem állnak rendelkezésre adott bemenetekhez tartozó elvárt válaszok, tehát a rendszer nem rendelkezik a tanító adatok halmazával. A rendszernek a bementek és kimenetek alapján kell valamilyen viselkedést kialakítania. A környezettől nem kap semmiféle visszajelzést annak érdekében, hogy a hálózat jól vagy rosszul viselkedik-e. Ezáltal megállapítható, hogy ezen algoritmusok legfőbb jelmezője az, hogy nem előre meghatározott képességekkel rendelkeznek, amelyek csak egy adott feladat elvégzésére elegendőek, hanem képesek arra, hogy folyamatosan fejlesszék képességeiket és ezáltal képesek legyenek alkalmazkodni új és ismeretlen környezetekhez.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A megerősítéses tanulás algoritmusok kipróbálásának alap lépései}\label{sec:MEGEROSITESESALOGRITMUSOK}

A megerősítéses tanulási\cite{reinfLearning} algoritmusok állapotmegfigyeléseken és jutalmakon alapulnak. Ez szintén az élő szervezetekre vezethető vissza, hiszen az állatok tapasztalatainak megszerzése is az idegrendszer állapotmegfigyelésein alapszik. Megfigyelhető például a kutyák esetében, ha egy forró tárgyhoz hozza ér hamar elkapja a mancsát, viszont még néhányszor próbálkozik. Majd néhány próbálkozás után megtanulja, hogy egy adott tárgy ha forró, ahhoz többet ne érjen hozza. 
Minden egyes algoritmus bizonyos számú epizódot hajt végre, mely rendelkezik bizonyos számú lépés sorozattal. Az algoritmusok futtatásának a célja, hogy egy optimális stratégiát alakítsanak ki a feladat megoldására illetve, hogy maximalizálják a jutalmakat. A jutalmak maximalizálása egyben a feladat elvégzésének a költségét minimalizálja.\cite{dynamicProg}

A megerősítéses tanulási algoritmusok általában egy előre definiált állapotból indulnak, az éppen aktuális problémának megfelelően. Mivel nincs semmilyen információjuk arról, hogy mi lenne a jó lépés így véletlen lépésekkel próbálkoznak. Minden egyes lépes után kiértékelik a kialakult állapotot, ezt nevezzük állapotmegfigyelésnek. Viszont a rendszernek nincs semmilyen tudomása arról, hogy a kialakult állapot jó vagy rossz. Így az algoritmusnak semmilyen alapja nem lesz arra, hogy milyen lépést kellene hozzon. Tehát az algoritmusnak szüksége van arra, hogy tudja, ha valami jó történt, illetve ha valami rossz. E miatt az egyes állapotokhoz különböző jutalmakat rendelnek. A jutalmak adása kezdetben valamilyen becslés alapján történik a jövőre nézve, ezt nevezik a jutalmak hosszútávú maximalizációjának. Egyes környezetekben a jutalmak csak a teszt végén jelennek meg, például a sakk esetén, míg más környezetben folyamatosan jönnek a jutalmak, például a pingpong esetén minden pont jutalomnak tekinthető.

A megerősítéses tanulási algoritmusok esetében három fő részt lehet elkülöníteni. Az \texttt{Agent}, azaz az Ügynök, ami valójában a tanulási algoritmus. Az \texttt{Environment}, azaz a Környezet, amely meghatározza az adott tesztet, például a sakk problémája. Az \texttt{Experiment}, azaz a Kísérlet, amely meghatározza az epizódok számát, illetve az epizódokon belül a lépések számát. E három fő részről és az ezek közötti kommunikáció részletesebb leírását az \ref{sec:AlapfogalmakBevezetese} szekció tartalmazza.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Kihívások a kísérletek futtatása során}
A megerősítéses tanulási algoritmusok futtatása saját számítógépen nem a legjobb megoldás. Ezen kísérletek futtatása egy időigényes folyamat lehet, például egy robot esetén, melynek teljes mozgását reprezentálni szeretnénk. A robot összes mozgásának reprezentálása nagyon sok lépést vehet igénybe, annak érdekében, hogy sikeresen kialakításra kerüljön az optimális mozgási stratégia. A kísérletek futtatása során felmerül az a probléma, hogy egy adott kísérlet több példányát  kellene végrehajtani egyidejűleg, illetve több különböző kísérlet példányait egyszerre mindezt online. Amennyiben egy kísérlet futási ideje több óra, nap esetleg hét is lehet, a fejlesztők nem várhatnak egy adott kísérlet befejezésére, hiszen akkor az előre haladás nagyon nagyon lassú lenne. Az időigényesség mellett fontos megemlíteni, hogy komplexebb szimulációs környezetek esetén, melyet egy komplex tanulási algoritmus irányít, nagyon nagy erőforrás igényre lehet szükség. Amennyiben már egy algoritmus végrehajtása nagy erőforrás igényű lehet, akkor több algoritmus egyidejű végrehajtása esetén óriási erőforrásigényekről beszélhetünk. A kísérletek nagy mennyiségű adatokat generálnak, melyekre a későbbi kiértékelés és esetleges összehasonlítások során szükség lehet. Ezen adatok tárolására, adatbázisokra lehet szükség a könnyed hozzáférés érdekében. Ezen kihívások azt eredményezik, hogy a számítógép állandóan be kell legyen kapcsolva, a nagy erőforrás igény miatt másra nem is lehetne használni, illetve nehezen managelhetőek lennének a tesztek.  

Ennek megoldására egy olyan szimulációs környezet megvalósítása kínál lehetőséget, amely egy távoli, jól felszerelt szervergépen fut, mely folyamatosan elérhető az interneten keresztül és rendelkezik a megfelelő erőforrásokkal. E környezet dinamikusan kell működjön, hiszen egyszerre több teszt futtatását kell lehetővé tegye. E mellett rendelkeznie kell valamilyen adatbázis kapcsolattal, ahova minden teszt esetén elmenti az adatokat. Ezen tulajdonságok mellett, elengedhetetlen a szimulációs környezet számára a könnyed bővíthetőség és módosíthatóság tulajdonsága, amely által a már meglévő kísérletek könnyedén megváltoztathatóak az új elképzelések alapján, illetve az új kísérletek hozzáadása könnyedén eszközölhető.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Alapfogalmak bevezetése}\label{sec:AlapfogalmakBevezetese}

A projekt megvalósítása során a szerző megismerte az  Rl-Glue projekt elveit és annak funkcionalitásait, melyek meghatározó szerepet töltenek be a RoboRun projektben is. A három alap komponens mindkét projekt esetén  az \texttt{Agent}(Ügynök), \texttt{Environment}(Környezet) és az \texttt{Experiment}(Kísérlet). Ezen komponensek egymással való interakciója révén nyílik lehetőségünk futtatni illetve tesztelni a megerősítéses tanulási algoritmusokat. 

	Az \texttt{Agent} komponens valójában a tanulási algoritmus, amely kiszabja a feladatokat és az ezekre vonatkozó megszorításokat egy adott iterációra vonatkozóan. Az \texttt{Agent} jutalmat(reward) kap minden egyes iteráció után arra vonatkozóan, hogy a probléma megoldásának szempontjából mennyire volt hatékony a kiszabott feladat, illetve az erre vonatkozó megszorítás. Mivel nem tudhatja az algoritmus, hogy melyik a helyes módszer a probléma megoldására, ezért találgatnia kell. Időnként új cselekvéseket is kell próbálnia, majd az ezekből megszerzett tudást, ami esetünkben a jutalom, optimális módon felhasználnia a következő cselekvés meghatározására. Például \texttt{RandomAgent}, mely valójában nem is tanulási algoritmus, hiszen véletlenszerű lépések alapján próbál az egyes környezetekben megoldást találni a problémára. Viszont gyakran használják egyes környezetek kipróbálására.
	
	Az \texttt{Environment} komponens feladata végrehajtani az \texttt{Agent} komponens által meghatározott feladatokat és az ezekre vonatkozó megszorításokat az adott problémára. A végrehajtás során következtetéseket(observation) von le minden egyes állapotról. Majd ezen következtetések alapján jutalmakat(reward) határoz meg. Mivel bizonytalan a környezet,    valami becslést kell alkalmaznia a jövőre nézve, így kezdetben lehet, hogy egy jó lépésért nem kapjuk meg a megfelelő jutalmat. Viszont minél jobban megismerjük a környezetet, annál pontosabb lesz egy lépésért vagy lépés sorozatért járó jutalom. A jutalom egy számban fejezhető ki, amely egy adott intervallumban mozog. Ha az intervallum felső határához közelít a szám akkor pozitív visszajelzést kaptunk az adott lépés vagy lépes sorozat után, amennyiben az intervallum alsó határához közelít a szám, negatív a visszajelzés. Például a \texttt{MountainCar} környezet, amelyben az a feladata a tanuló algoritmusnak, hogy egy bizonyos kezdeti pozícióból eljusson egy kijelölt végső pozícióba a lehető leggyorsabban. Ehhez meg kell tanulnia a szakadékban előre és hátra mennie egészen addig, amíg olyan sebességre tesz szert, hogy elegendő a végpontba való eljutáshoz.
	
	Az \texttt{Experiment} komponens irányítja a teljes kísérlet végrehajtását. E komponens nincs direkt kapcsolatban az \texttt{Agent} és az \texttt{Environment} komponensekkel. Van köztük egy köztes réteg, amely végzi a kommunikációt e három komponens között.  Az \texttt{Experiment} komponensben van meghatározva a lépések száma egy adott iterációban, illetve az iterációk száma is. Fontos azon szerepe is az \texttt{Experiment} komponensnek, hogy a végső eredményeket ő kapja meg az \texttt{Agent} illetve az \texttt{Environment} komponensektől a köztes rétegen keresztül.
A fent említett köztes réteg az Rl-Glue projekt esetén az úgynevezett RL-Glue mely a teljes kommunikáció lebonyolítását végzi a komponensek között illetve létrehozza a hálózati kommunikációhoz szükséges objektumokat. Az Rl-Glue projekt alap kommunikációját az \texttt{Agent}, \texttt{Environment}, \texttt{Experiment} és \texttt{RL-Glue} között a \ref{fig:RlGlueKommunikacio} ábra szemlélteti.

\begin{figure}[h!]
  \centering
  \pgfimage[width=0.7\linewidth]{images/glueConnection}
  \caption[Példa képek beszúrására]%
  {Rl-Glue projekt komponensek közti kommunikációja:\\
  {\white .}\hfill\url{http://rl-glue.googlecode.com/svn/trunk/docs/html/index.html}}
  \label{fig:RlGlueKommunikacio}
\end{figure}

A RoboRun projekt esetén az RL-Glue komponens helyét felváltja a \texttt{RoboCommunication} komponens, a funkcionalitásokat tekintve az alap ötlet megmaradt viszont számos új dologgal ki lett bővítve, illetve új funkcionalitások kerülnek használatra. Számos funkcionalitás található az RL-Glue projektben, amelyre a RoboRun projektben nincs szükség, így ezen funkcionalitások teljesen ki lettek hagyva. Ilyen például a hálózat alapú kommunikáció.

	Az \texttt{Agent}, \texttt{Environment}, \texttt{Experiment} és a \texttt{RoboCommunication}  komponensek interakciójának sorrendje hasonlóan működik, mint az Rl - Glue projektben megvalósított elgondolás, viszont a RoboRun projekt esetén minden egyes komponens  egy szolgáltatás az OSGi konténerben, amelyek képesek egymással kapcsolatba lépni az OSGi szolgáltatásokon keresztül, így megvalósítva a dinamikus, komponens alapú modell kivitelezését és a több teszt egy időben való futtatási lehetőségét. E mellett ezen szolgáltatások elérése korlátozott, a többi szolgáltatás számára, amely biztonsági okokból is előnyös a rendszerre nézve. Az OSGi konténer futtatásáért egy GlassFish\citep{glassfish} szerver a felelős. Az OSGi specifikáció részletes ismertetése a \ref{ch:OSGI} fejezetben olvasható.
	
	 A konténerben egyszerre több előre definiált \texttt{Agent} és \texttt{Environment} lehet telepítve, ezek száma nincs korlátozva, annyi telepíthető belőlük amennyi még nem okoz gondot a szervert futtató számítógép hardver konfigurációjának. Bármikor módosítható, törölhető vagy teljesen új \texttt{Agent} és \texttt{Environment} is hozzáadható a konténerhez anélkül, hogy a szervert meg kellene állítani vagy újra kellene indítani. A \texttt{RoboCommunication} komponensből egyet tartalmaz a rendszer, hiszen ez az egy szolgáltatás képes kielégíteni számtalan \texttt{Agent} és \texttt{Environment} komponens példányt egy időben, mindezt a projekt architektúrájának és az OSGi keretrendszerben rejlő lehetőségek által. Az Experimentekből is egyszerre több lehet telepítve, hiszen ezek felelnek egy egy teszt indításáért. Egyszerre több tesztet is lehet indítani, vagy lehetőség van arra is, hogy különböző időközönként telepítsünk egy- egy \texttt{Experiment} komponenst. A RoboRun projekt alap komponensei közötti kommunikációt szemlélteti a \ref{fig:OsgiAlap} ábra.

\begin{figure}[h!]
  \centering
  \pgfimage[width=1\linewidth]{images/alapKomponens}
  \caption[RoboRun alap komponensek]%
  {A RoboRun projekt alap komponensek közti kommunikáció:\\
  {\white .}\hfill\url{}}
  \label{fig:OsgiAlap}
\end{figure}


Egy kísérlet futtatásához szükségünk van egy \texttt{Agent}, egy \texttt{Environment}, egy \texttt{Experiment} és egy \texttt{RoboCommunication} komponensre. A \texttt{RoboCommunication} komponens esetén még szükség van néhány függőségre az adatbázishoz való hozzáférés biztosítására, illetve a webes felület adatainak féltöltésé érdekében, ezekről részletesebben \ref{ch:Felepites} fejezetben lehet megismerkedni. A kísérlet belépési pontjaként az Experiment komponens szolgál, hiszen ő határozza meg, hogy melyik \texttt{Agent}, illetve \texttt{Environment} példánnyal szeretne dolgozni, illetve az \texttt{Experiment} határozza meg a szükséges lépések számát iterációnként és az iterációk számát. Az \texttt{Experiment} komponens lekérdezi a szükséges szolgáltatásokat és átadja a RoboCommunication szolgáltatásnak a lekérdezett \texttt{Agent} és \texttt{Environment} szolgáltatás példányokat. A \texttt{RoboCommunication} komponens fogja biztosítani e három komponens között a folyamatos kommunikációt a teszt futtatása során. A tesztek állapotának nyomon követésére lehetőség van a webes felületen keresztül, illetve a tesztek befejeztével megtekinthetőek a futása során létrejött adatok.

	A projekt architektúrája követi a OSGi szabványokat, így minden szolgáltatásnak implementálnia kell egy interfészt, mely egy külön batyuban található. Az interfész közzéteszi a szolgáltatások számára a csomagját. A csomag importálása által a szolgáltatások megvalósíthatják az adott interfészt. Minden egyes \texttt{Agent} kötelező módon implementálja az \texttt{AgentInterface} -t és minden \texttt{Environment} kötelező módon implementálja az \texttt{EnvironmentInterface} -t. Ez által valósul meg a szimulációs környezet egységessége, amely egy egyedi konvencióra épül. Nem létezhet olyan \texttt{Agent} vagy \texttt{Environment} példány a rendszerben, amely nem implementálja a neki megfelelő interfészt. Amennyiben mégis telepítésre kerül egy ilyen szolgáltatás, nem fog működni, mert egy szolgáltatás lekérdezése csak az általa implementált interfész által lehetséges. Az interfészek és a hozzájuk tartozó implementációkat a \ref{fig:alapUML} ábra szemléltet.

\begin{figure}[h]
  \centering
  \pgfimage[width=1\linewidth]{images/alapUML}
  \caption[Példa képek beszúrására]%
  {Agent és Environment Interfész és implementáció\\
  {\white .}\hfill\url{}}
  \label{fig:alapUML}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
